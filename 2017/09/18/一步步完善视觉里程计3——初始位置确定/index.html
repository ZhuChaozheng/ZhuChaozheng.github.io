<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>一步步完善视觉里程计3——初始位置确定 | BlackAnt</title>
  <meta name="author" content="ZhuChaozheng SunTong ChuZhefan">
  
  <meta name="description" content="This website is designed by x-space, and use to offer a professional robot solutions.">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="一步步完善视觉里程计3——初始位置确定"/>
  <meta property="og:site_name" content="BlackAnt"/>

  
    <meta property="og:image" content=""/>
  

  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <link rel="alternate" href="/atom.xml" title="BlackAnt" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

  
<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?77ef4451b3a9c64e7da624afdd20490e";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">BlackAnt</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/new-page">Blog</a></li>
    
      <li><a href="/about">about</a></li>
    
	<li> <a title="把这个链接拖到你的Chrome收藏夹工具栏中" href='javascript:(function() {
	function c() {
		var e = document.createElement("link");
		e.setAttribute("type", "text/css");
		e.setAttribute("rel", "stylesheet");
		e.setAttribute("href", f);
		e.setAttribute("class", l);
		document.body.appendChild(e)
	}
 
	function h() {
		var e = document.getElementsByClassName(l);
		for (var t = 0; t < e.length; t++) {
			document.body.removeChild(e[t])
		}
	}
 
	function p() {
		var e = document.createElement("div");
		e.setAttribute("class", a);
		document.body.appendChild(e);
		setTimeout(function() {
			document.body.removeChild(e)
		}, 100)
	}
 
	function d(e) {
		return {
			height : e.offsetHeight,
			width : e.offsetWidth
		}
	}
 
	function v(i) {
		var s = d(i);
		return s.height > e && s.height < n && s.width > t && s.width < r
	}
 
	function m(e) {
		var t = e;
		var n = 0;
		while (!!t) {
			n += t.offsetTop;
			t = t.offsetParent
		}
		return n
	}
 
	function g() {
		var e = document.documentElement;
		if (!!window.innerWidth) {
			return window.innerHeight
		} else if (e && !isNaN(e.clientHeight)) {
			return e.clientHeight
		}
		return 0
	}
 
	function y() {
		if (window.pageYOffset) {
			return window.pageYOffset
		}
		return Math.max(document.documentElement.scrollTop, document.body.scrollTop)
	}
 
	function E(e) {
		var t = m(e);
		return t >= w && t <= b + w
	}
 
	function S() {
		var e = document.createElement("audio");
		e.setAttribute("class", l);
		e.src = i;
		e.loop = false;
		e.addEventListener("canplay", function() {
			setTimeout(function() {
				x(k)
			}, 500);
			setTimeout(function() {
				N();
				p();
				for (var e = 0; e < O.length; e++) {
					T(O[e])
				}
			}, 15500)
		}, true);
		e.addEventListener("ended", function() {
			N();
			h()
		}, true);
		e.innerHTML = " <p>If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.</p> <p>";
		document.body.appendChild(e);
		e.play()
	}
 
	function x(e) {
		e.className += " " + s + " " + o
	}
 
	function T(e) {
		e.className += " " + s + " " + u[Math.floor(Math.random() * u.length)]
	}
 
	function N() {
		var e = document.getElementsByClassName(s);
		var t = new RegExp("\\b" + s + "\\b");
		for (var n = 0; n < e.length; ) {
			e[n].className = e[n].className.replace(t, "")
		}
	}
 
	var e = 30;
	var t = 30;
	var n = 350;
	var r = 350;
	var i = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake.mp3";
	var s = "mw-harlem_shake_me";
	var o = "im_first";
	var u = ["im_drunk", "im_baked", "im_trippin", "im_blown"];
	var a = "mw-strobe_light";
	var f = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css";
	var l = "mw_added_css";
	var b = g();
	var w = y();
	var C = document.getElementsByTagName("*");
	var k = null;
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			if (E(A)) {
				k = A;
				break
			}
		}
	}
	if (A === null) {
		console.warn("Could not find a node of the right size. Please try a different page.");
		return
	}
	c();
	S();
	var O = [];
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			O.push(A)
		}
	}
})()    '>High一下</a> </li>
	<li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-09-18T12:09:26.000Z"><a href="/2017/09/18/一步步完善视觉里程计3——初始位置确定/">2017-09-18</a></time>
      
      
  
    <h1 class="title">一步步完善视觉里程计3——初始位置确定</h1>
  

    </header>
    <div class="entry">
      
        <p><strong>前面一篇博客，我们已经进行了特征提取，前面我们也说了，我们接下来不是通过特征匹配的方式来寻找对应特征点，而是采用跟踪的方式。<br>在前面视觉里程计总述中讲诉了误差的累计，因此初始位置的确定显得尤为重要，要确保初始位置的尽可能的准确。这一篇博客主要讲述了如何更精确的确定初始位置。</strong><a id="more"></a></p>
<h2 id="sophus库的添加"><a href="#sophus库的添加" class="headerlink" title="sophus库的添加"></a>sophus库的添加</h2><p>对于<strong>sophus</strong>，目前我理解的范围就是对旋转和平移做了一个封装，可以更好的进行刚性变换。为了更方便的看懂，这里使用了<strong>sophus</strong>的非模板的版本，通过<em>git clone <a href="https://github.com/strasdat/Sophus.git" target="_blank" rel="external">https://github.com/strasdat/Sophus.git</a></em>后继续<em>git checkout a621ff</em><br>这边编译在vs2013上报错，在文件so2.cpp中，修改如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">SO2::SO2()</div><div class="line">&#123;</div><div class="line">//unit_complex_.real() = 1.;</div><div class="line">//unit_complex_.imag() = 0.;</div><div class="line">unit_complex_.real(1.);	</div><div class="line">unit_complex_.imag(0.);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>对于李群李代数后续需进一步学习。</strong></p>
<h2 id="初始位置确定"><a href="#初始位置确定" class="headerlink" title="初始位置确定"></a>初始位置确定</h2><p>初始位置的确定的基本思路，根据光流确定对应特征点，根据对应特征点计算两帧之间的单应矩阵，根据单应矩阵进行分解，计算出两帧之间的旋转和平移。<br>考虑到帧的旋转和平移，则在帧上添加属性,添加从世界坐标系(w)orld转到摄像机坐标系(f)rame的刚性变换<strong>Rt Sophus::SE3 Tf_w;</strong>，而对于特征添加特征对应的3D点，以及特征的单位方向向量（用于后期的三角定位），具体添加如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Vector3d f;           //!&lt; 特征的单位方向向量</div><div class="line">Point3D* point;       //!&lt; 指针指向跟特征对应的3D点</div></pre></td></tr></table></figure>
<p>这里我们构建Point3D这个类，用于表示特征所对应的3D点，具体定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">class Point3D : Noncopyable</div><div class="line">&#123;</div><div class="line">public:</div><div class="line">EIGEN_MAKE_ALIGNED_OPERATOR_NEW</div><div class="line"></div><div class="line">Point3D(const Vector3d&amp; pos);</div><div class="line">~Point3D();</div><div class="line">/// 添加特征到一个帧中</div><div class="line">void addFrameRef(Feature* ftr);</div><div class="line"></div><div class="line">public:</div><div class="line">static int    point_counter_; //!&lt; 创建点的计数，用于设置唯一的id</div><div class="line">int           id_;            //!&lt; 点唯一的id</div><div class="line">Vector3d      pos_;           //!&lt; 点在世界坐标系中的位置</div><div class="line">std::list&lt;Feature*&gt;   obs_;   //!&lt; 对应这个点的特征</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>这样新的数据结构就修改和添加完成，我们接下来要做的事情就是进行整合。</p>
<h2 id="选择第一帧"><a href="#选择第一帧" class="headerlink" title="选择第一帧"></a>选择第一帧</h2><p>为了更好的确定初始位置，我们对第一帧的选择有一定的限制条件，我们要确保第一帧的图像中检测到的特征数大于100个。只有满足这样的条件，我们可以方便的进行下一步的特征跟踪，具体实现如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">InitResult Initialization::addFirstFrame(FramePtr frame_ref)</div><div class="line">&#123;</div><div class="line">reset();</div><div class="line">detectFeatures(frame_ref, px_ref_, f_ref_);</div><div class="line">if (px_ref_.size() &lt; 100)</div><div class="line">&#123;</div><div class="line">std::cerr &lt;&lt; &quot;First image has less than 100 features. Retry in more textured environment.&quot; &lt;&lt; std::endl;</div><div class="line">return FAILURE;</div><div class="line">&#125;</div><div class="line">// 将这一帧图像做为参考帧</div><div class="line">frame_ref_ = frame_ref;</div><div class="line">// 先设置当前帧的特征与参考帧的特征一致</div><div class="line">px_cur_.insert(px_cur_.begin(), px_ref_.begin(), px_ref_.end());</div><div class="line">return SUCCESS;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这边根据当前帧可以检测到特征点的位置，以及获得特征的单位向量，具体可以参考：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">/// 检测fast角度，输出的是对应的点和点的方向向量（可以考虑为点的反投影坐标）</div><div class="line">void Initialization::detectFeatures(</div><div class="line">FramePtr frame,</div><div class="line">std::vector&lt;cv::Point2f&gt;&amp; px_vec,</div><div class="line">std::vector&lt;Vector3d&gt;&amp; f_vec)</div><div class="line">&#123;</div><div class="line">Features new_features;</div><div class="line">FastDetector detector(</div><div class="line">frame-&gt;img().cols, frame-&gt;img().rows, 25, 3);</div><div class="line">detector.detect(frame.get(), frame-&gt;img_pyr_, 20.0, new_features);</div><div class="line"></div><div class="line">// 返回特征位置和特征的单位向量</div><div class="line">px_vec.clear(); px_vec.reserve(new_features.size());</div><div class="line">f_vec.clear(); f_vec.reserve(new_features.size());</div><div class="line">std::for_each(new_features.begin(), new_features.end(), [&amp;](Feature* ftr)&#123;</div><div class="line">px_vec.push_back(cv::Point2f(ftr-&gt;px[0], ftr-&gt;px[1]));</div><div class="line">f_vec.push_back(ftr-&gt;f);</div><div class="line">delete ftr;</div><div class="line">&#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<pre><code>这边有一个疑惑，本来打算对帧frame类中的属性list修改为list,
</code></pre><p>这样就避免了目前对Feature new和delete不在一起的状况。<br>但是修改之后会报错，报错在对特征对象进行push_back的时候，目前还是仿作者采用指针的方式，后期进行修改。</p>
<h2 id="选择第二帧"><a href="#选择第二帧" class="headerlink" title="选择第二帧"></a>选择第二帧</h2><h2 id="特征跟踪"><a href="#特征跟踪" class="headerlink" title="特征跟踪"></a>特征跟踪</h2><p>第一帧确定好了之后，然后通过金字塔Lucas-Kanade光流方法计算前期特征的光流（稀疏光流），具体使用OpenCV的方法calcOpticalFlowPyrLK，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">void Initialization::trackKlt(</div><div class="line">FramePtr frame_ref,</div><div class="line">FramePtr frame_cur,</div><div class="line">std::vector&lt;cv::Point2f&gt;&amp; px_ref,</div><div class="line">std::vector&lt;cv::Point2f&gt;&amp; px_cur,</div><div class="line">std::vector&lt;Vector3d&gt;&amp; f_ref,</div><div class="line">std::vector&lt;Vector3d&gt;&amp; f_cur,</div><div class="line">std::vector&lt;double&gt;&amp; disparities)</div><div class="line">&#123;</div><div class="line">const double klt_win_size = 30.0;</div><div class="line">const int klt_max_iter = 30;</div><div class="line">const double klt_eps = 0.001;</div><div class="line">std::vector&lt;uchar&gt; status;</div><div class="line">std::vector&lt;float&gt; error;</div><div class="line">std::vector&lt;float&gt; min_eig_vec;</div><div class="line">cv::TermCriteria termcrit(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, klt_max_iter, klt_eps);</div><div class="line">cv::calcOpticalFlowPyrLK(frame_ref-&gt;img_pyr_[0], frame_cur-&gt;img_pyr_[0],</div><div class="line">px_ref, px_cur,</div><div class="line">status, error,</div><div class="line">cv::Size2i(klt_win_size, klt_win_size),</div><div class="line">4, termcrit, 0);//cv::OPTFLOW_USE_INITIAL_FLOW</div><div class="line"></div><div class="line">std::vector&lt;cv::Point2f&gt;::iterator px_ref_it = px_ref.begin();</div><div class="line">std::vector&lt;cv::Point2f&gt;::iterator px_cur_it = px_cur.begin();</div><div class="line">std::vector&lt;Vector3d&gt;::iterator f_ref_it = f_ref.begin();</div><div class="line">f_cur.clear(); f_cur.reserve(px_cur.size());</div><div class="line">disparities.clear(); disparities.reserve(px_cur.size());</div><div class="line">for (size_t i = 0; px_ref_it != px_ref.end(); ++i)</div><div class="line">&#123;</div><div class="line">if (!status[i])//如果光流没有发现，则删除</div><div class="line">&#123;</div><div class="line">px_ref_it = px_ref.erase(px_ref_it);</div><div class="line">px_cur_it = px_cur.erase(px_cur_it);</div><div class="line">f_ref_it = f_ref.erase(f_ref_it);</div><div class="line">continue;</div><div class="line">&#125;</div><div class="line">f_cur.push_back(frame_cur-&gt;c2f(px_cur_it-&gt;x, px_cur_it-&gt;y));//添加当前特征对应的单位向量</div><div class="line">disparities.push_back(Vector2d(px_ref_it-&gt;x - px_cur_it-&gt;x, px_ref_it-&gt;y - px_cur_it-&gt;y).norm());//添加对应特征之间的距离</div><div class="line">++px_ref_it;</div><div class="line">++px_cur_it;</div><div class="line">++f_ref_it;</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><br>主要通过跟踪确定下一帧特征的估计位置以及估计特征的单位向量。<br>而对于跟踪的特征数目要大于50，对于金字塔Lucas-Kanade光流方法的参数调节，后续根据论文及实验进行测试。<br>在<strong>视觉里程计总述</strong>里面介绍到关键帧，给出图的形式表示两帧的距离很近会影响3D点的准确度。在这里对上述disparities的中值做一个阈值限制，如果其中值小于50，则认为选择的帧不是关键帧，不能进行3D点估计。具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">InitResult Initialization::addSecondFrame(FramePtr frame_cur)</div><div class="line">&#123;</div><div class="line">trackKlt(frame_ref_, frame_cur, px_ref_, px_cur_, f_ref_, f_cur_, disparities_);</div><div class="line">std::cout &lt;&lt; &quot;Init: KLT tracked &quot; &lt;&lt; disparities_.size() &lt;&lt; &quot; features&quot; &lt;&lt; std::endl;</div><div class="line"></div><div class="line">// 符合光流跟踪的特征数</div><div class="line">if (disparities_.size() &lt; 50)</div><div class="line">return FAILURE;</div><div class="line"></div><div class="line">// 对两帧光流跟踪之后像素差值的中值</div><div class="line">double disparity = getMedian(disparities_);</div><div class="line">std::cout &lt;&lt; &quot;Init: KLT &quot; &lt;&lt; disparity &lt;&lt; &quot;px average disparity.&quot; &lt;&lt; std::endl;</div><div class="line">//  如果中值小于给定配置参数，则表明这一帧不是关键帧，也就是刚开始的时候两帧不能太近</div><div class="line">if (disparity &lt; 50.0)</div><div class="line">return NO_KEYFRAME;</div><div class="line">//  计算单应矩阵</div><div class="line">computeHomography(</div><div class="line">f_ref_, f_cur_,</div><div class="line">frame_ref_-&gt;cam_-&gt;getFocalLength(), 2.0,</div><div class="line">inliers_, xyz_in_cur_, T_cur_from_ref_);</div><div class="line">......</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>接下来进行单应矩阵估计和分解，这边新建Homography类，用于处理单应矩阵估计和分解。具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">bool Homography::computeSE3fromMatches()</div><div class="line">&#123;</div><div class="line">calcFromMatches();//计算单应</div><div class="line">bool res = decompose();// 将单应矩阵进行分解</div><div class="line">if (!res)</div><div class="line">return false;</div><div class="line">computeMatchesInliers();// 计算匹配的内点数</div><div class="line">findBestDecomposition();// 找出最好的分解</div><div class="line">T_c2_from_c1 = decompositions[0].T;</div><div class="line">return true;</div><div class="line">&#125;</div></pre></td></tr></table></figure><br>首先先计算单应矩阵，目前采用OpenCV的函数cv::findHomography来进行计算，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">void Homography::calcFromMatches()</div><div class="line">&#123;</div><div class="line">std::vector&lt;cv::Point2f&gt; src_pts(fts_c1_.size()), dst_pts(fts_c1_.size());</div><div class="line">for (size_t i = 0; i &lt; fts_c1_.size(); ++i)</div><div class="line">&#123;</div><div class="line">src_pts[i] = cv::Point2f(fts_c1_[i][0], fts_c1_[i][1]);</div><div class="line">dst_pts[i] = cv::Point2f(fts_c2_[i][0], fts_c2_[i][1]);</div><div class="line">&#125;</div><div class="line"></div><div class="line">cv::Mat cvH = cv::findHomography(src_pts, dst_pts, CV_RANSAC, 2. / focal_length_);</div><div class="line">H_c2_from_c1_(0, 0) = cvH.at&lt;double&gt;(0, 0);</div><div class="line">H_c2_from_c1_(0, 1) = cvH.at&lt;double&gt;(0, 1);</div><div class="line">H_c2_from_c1_(0, 2) = cvH.at&lt;double&gt;(0, 2);</div><div class="line">H_c2_from_c1_(1, 0) = cvH.at&lt;double&gt;(1, 0);</div><div class="line">H_c2_from_c1_(1, 1) = cvH.at&lt;double&gt;(1, 1);</div><div class="line">H_c2_from_c1_(1, 2) = cvH.at&lt;double&gt;(1, 2);</div><div class="line">H_c2_from_c1_(2, 0) = cvH.at&lt;double&gt;(2, 0);</div><div class="line">H_c2_from_c1_(2, 1) = cvH.at&lt;double&gt;(2, 1);</div><div class="line">H_c2_from_c1_(2, 2) = cvH.at&lt;double&gt;(2, 2);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>这边注意了，对于cv::findHomography的参数ransacReprojThreshold，这边单位不是像素，有1/focal_length的scale</strong>，更详细的使用参考：<br><img src="http://7xl6tk.com1.z0.glb.clouddn.com/findHomography.png" alt=""><br>下一步进行单应矩阵分解，具体过程可以参考[1]，具体代码实现参考：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div></pre></td><td class="code"><pre><div class="line">bool Homography::decompose()</div><div class="line">&#123;</div><div class="line">decomp_size_ = 0;</div><div class="line">JacobiSVD&lt;MatrixXd&gt; svd(H_c2_from_c1_, ComputeThinU | ComputeThinV);</div><div class="line">Vector3d singular_values = svd.singularValues();</div><div class="line">// 获得3个特征量</div><div class="line">double d1 = fabs(singular_values[0]); </div><div class="line">double d2 = fabs(singular_values[1]); </div><div class="line">double d3 = fabs(singular_values[2]);</div><div class="line"></div><div class="line">Matrix3d U = svd.matrixU();</div><div class="line">Matrix3d V = svd.matrixV();                    // VT^T</div><div class="line"></div><div class="line">double s = U.determinant() * V.determinant();</div><div class="line"></div><div class="line">double dPrime_PM = d2;</div><div class="line"></div><div class="line">int nCase;</div><div class="line">if (d1 != d2 &amp;&amp; d2 != d3)</div><div class="line">nCase = 1;</div><div class="line">else if (d1 == d2 &amp;&amp; d2 == d3)</div><div class="line">nCase = 3;</div><div class="line">else</div><div class="line">nCase = 2;</div><div class="line">if (nCase != 1)</div><div class="line">&#123;</div><div class="line">printf(&quot;FATAL Homography Initialization: This motion case is not implemented or is degenerate. Try again. &quot;);</div><div class="line">return false;</div><div class="line">&#125;</div><div class="line"></div><div class="line">double x1_PM;</div><div class="line">double x2;</div><div class="line">double x3_PM;</div><div class="line">// 在情况1下(d1 != d3)</div><div class="line">&#123; // Eq. 12</div><div class="line">x1_PM = sqrt((d1*d1 - d2*d2) / (d1*d1 - d3*d3));</div><div class="line">x2 = 0;</div><div class="line">x3_PM = sqrt((d2*d2 - d3*d3) / (d1*d1 - d3*d3));</div><div class="line">&#125;;</div><div class="line"></div><div class="line">double e1[4] = &#123; 1.0, -1.0, 1.0, -1.0 &#125;;</div><div class="line">double e3[4] = &#123; 1.0, 1.0, -1.0, -1.0 &#125;;</div><div class="line"></div><div class="line">Vector3d np;</div><div class="line">HomographyDecomposition decomp;</div><div class="line"></div><div class="line">// Case 1, d&apos; &gt; 0:</div><div class="line">decomp.d = s * dPrime_PM;</div><div class="line">for (size_t signs = 0; signs &lt; 4; signs++)</div><div class="line">&#123;</div><div class="line">// Eq 13</div><div class="line">decomp.R = Matrix3d::Identity();</div><div class="line">double dSinTheta = (d1 - d3) * x1_PM * x3_PM * e1[signs] * e3[signs] / d2;</div><div class="line">double dCosTheta = (d1 * x3_PM * x3_PM + d3 * x1_PM * x1_PM) / d2;</div><div class="line">decomp.R(0, 0) = dCosTheta;</div><div class="line">decomp.R(0, 2) = -dSinTheta;</div><div class="line">decomp.R(2, 0) = dSinTheta;</div><div class="line">decomp.R(2, 2) = dCosTheta;</div><div class="line">// Eq 14</div><div class="line">decomp.t[0] = (d1 - d3) * x1_PM * e1[signs];</div><div class="line">decomp.t[1] = 0.0;</div><div class="line">decomp.t[2] = (d1 - d3) * -x3_PM * e3[signs];</div><div class="line">np[0] = x1_PM * e1[signs];</div><div class="line">np[1] = x2;</div><div class="line">np[2] = x3_PM * e3[signs];</div><div class="line">decomp.n = V * np;</div><div class="line">decompositions_[decomp_size_++] = decomp;</div><div class="line">&#125;</div><div class="line"></div><div class="line">// Case 1, d&apos; &lt; 0:</div><div class="line">decomp.d = s * -dPrime_PM;</div><div class="line">for (size_t signs = 0; signs &lt; 4; signs++)</div><div class="line">&#123;</div><div class="line">// Eq 15</div><div class="line">decomp.R = -1 * Matrix3d::Identity();</div><div class="line">double dSinPhi = (d1 + d3) * x1_PM * x3_PM * e1[signs] * e3[signs] / d2;</div><div class="line">double dCosPhi = (d3 * x1_PM * x1_PM - d1 * x3_PM * x3_PM) / d2;</div><div class="line">decomp.R(0, 0) = dCosPhi;</div><div class="line">decomp.R(0, 2) = dSinPhi;</div><div class="line">decomp.R(2, 0) = dSinPhi;</div><div class="line">decomp.R(2, 2) = -dCosPhi;</div><div class="line"></div><div class="line">// Eq 16</div><div class="line">decomp.t[0] = (d1 + d3) * x1_PM * e1[signs];</div><div class="line">decomp.t[1] = 0.0;</div><div class="line">decomp.t[2] = (d1 + d3) * x3_PM * e3[signs];</div><div class="line"></div><div class="line">np[0] = x1_PM * e1[signs];</div><div class="line">np[1] = x2;</div><div class="line">np[2] = x3_PM * e3[signs];</div><div class="line">decomp.n = V * np;</div><div class="line"></div><div class="line">decompositions_[decomp_size_++] = decomp;</div><div class="line">&#125;</div><div class="line"></div><div class="line">// 保存分解之后的旋转和平移，Eq 8</div><div class="line">for (unsigned int i = 0; i &lt; decomp_size_; i++)</div><div class="line">&#123;</div><div class="line">Matrix3d R = s * U * decompositions_[i].R * V.transpose();</div><div class="line">Vector3d t = U * decompositions_[i].t;</div><div class="line">decompositions_[i].T = Sophus::SE3(R, t);</div><div class="line">&#125;</div><div class="line">return true;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过svd分解，根据特征值条件，构建了8组理论解。下一步就是找到最好的分解，在此之前先找到内点数（也就是图像中符合计算出的单应矩阵的特征点），通过内点来进行验证。具体给内点打上标识，过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">size_t Homography::computeMatchesInliers()</div><div class="line">&#123;</div><div class="line">inliers_.clear(); inliers_.resize(fts_c1_.size());</div><div class="line">size_t n_inliers = 0;</div><div class="line">for (size_t i = 0; i &lt; fts_c1_.size(); i++)</div><div class="line">&#123;</div><div class="line">Vector2d projected = project2d(H_c2_from_c1_ * unproject2d(fts_c1_[i]));</div><div class="line">Vector2d e = fts_c2_[i] - projected;</div><div class="line">double e_px = focal_length_ * e.norm();//化为像素距离</div><div class="line">inliers_[i] = (e_px &lt; thresh_);//也就是残差在阈值范围内</div><div class="line">n_inliers += inliers_[i];</div><div class="line">&#125;</div><div class="line">return n_inliers;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面根据两个判断，1、特征点在摄像机的前面，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">for (size_t i = 0; i &lt; decomp_size_; i++)</div><div class="line">&#123;</div><div class="line">HomographyDecomposition &amp;decom = decompositions_[i];</div><div class="line">int positive = 0;</div><div class="line">for (size_t m = 0; m &lt; fts_c1_.size(); m++)</div><div class="line">&#123;</div><div class="line">if (!inliers_[m])</div><div class="line">continue;</div><div class="line">const Vector2d&amp; v2 = fts_c1_[m];</div><div class="line">double visibility_test = (H_c2_from_c1_(2, 0) * v2[0] + H_c2_from_c1_(2, 1) * v2[1] + H_c2_from_c1_(2, 2)) / decom.d;</div><div class="line">if (visibility_test &gt; 0.0)</div><div class="line">positive++;</div><div class="line">&#125;</div><div class="line">decom.score = -positive;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>2、通过参考平面的法向量与摄像机光线方向的夹角小于90度来进一步过滤。具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">for (size_t i = 0; i &lt; decomp_size_; i++)</div><div class="line">&#123;</div><div class="line">HomographyDecomposition &amp;decom = decompositions_[i];</div><div class="line">int positive = 0;</div><div class="line">for (size_t m = 0; m &lt; fts_c1_.size(); m++)</div><div class="line">&#123;</div><div class="line">if (!inliers_[m])</div><div class="line">continue;</div><div class="line">Vector3d v3 = unproject2d(fts_c1_[m]);</div><div class="line">double visibility_test = v3.dot(decom.n) / decom.d;</div><div class="line">if (visibility_test &gt; 0.0)</div><div class="line">positive++;</div><div class="line">&#125;;</div><div class="line">decom.score = -positive;</div><div class="line">&#125;</div></pre></td></tr></table></figure><br>提示：点乘为负，则说明夹角大于90度。<br>这样就剩下了2组可能的姿态，最后通过对上述计算的score计算比如，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">double ratio = (double)decompositions_[1].score / (double)decompositions_[0].score;</div></pre></td></tr></table></figure></p>
<p>如果ratio的值小于0.9，则确定了分解，如果大于0.9，则通过计算的R,tR,t计算本质矩阵后计算sampsonus error来进行判断。<strong>不过这边计算sampsonus error不是很明白为什么这么计算，有明白的，还望不吝赐教</strong>，具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">double sampsonusError(const Vector2d &amp;v2Dash, const Matrix3d&amp; essential, const Vector2d&amp; v2)</div><div class="line">&#123;</div><div class="line">Vector3d v3Dash = unproject2d(v2Dash);</div><div class="line">Vector3d v3 = unproject2d(v2);</div><div class="line"></div><div class="line">double error = v3Dash.transpose() * essential * v3;</div><div class="line"></div><div class="line">Vector3d fv3 = essential * v3;</div><div class="line">Vector3d fTv3Dash = essential.transpose() * v3Dash;</div><div class="line"></div><div class="line">Vector2d fv3Slice = fv3.head&lt;2&gt;();</div><div class="line">Vector2d fTv3DashSlice = fTv3Dash.head&lt;2&gt;();</div><div class="line"></div><div class="line">return (error * error / (fv3Slice.dot(fv3Slice) + fTv3DashSlice.dot(fTv3DashSlice)));</div><div class="line">&#125;</div></pre></td></tr></table></figure><br>分解结束之后计算内点和三角定点计算3D点，具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">void Initialization::computeHomography(</div><div class="line">const std::vector&lt;Vector3d&gt;&amp; f_ref,</div><div class="line">const std::vector&lt;Vector3d&gt;&amp; f_cur,</div><div class="line">double focal_length,</div><div class="line">double reprojection_threshold,</div><div class="line">std::vector&lt;int&gt;&amp; inliers,</div><div class="line">std::vector&lt;Vector3d&gt;&amp; xyz_in_cur,</div><div class="line">SE3&amp; T_cur_from_ref)</div><div class="line">&#123;</div><div class="line">std::vector&lt;Vector2d, aligned_allocator&lt;Vector2d&gt; &gt; uv_ref(f_ref.size());</div><div class="line">std::vector&lt;Vector2d, aligned_allocator&lt;Vector2d&gt; &gt; uv_cur(f_cur.size());</div><div class="line">for (size_t i = 0, i_max = f_ref.size(); i &lt; i_max; ++i)</div><div class="line">&#123;</div><div class="line">uv_ref[i] = project2d(f_ref[i]);</div><div class="line">uv_cur[i] = project2d(f_cur[i]);</div><div class="line">&#125;</div><div class="line">Homography Homography(uv_ref, uv_cur, focal_length, reprojection_threshold);</div><div class="line">Homography.computeSE3fromMatches();</div><div class="line">std::vector&lt;int&gt; outliers;</div><div class="line">computeInliers(f_cur, f_ref,</div><div class="line">Homography.T_c2_from_c1_.rotation_matrix(), Homography.T_c2_from_c1_.translation(),</div><div class="line">reprojection_threshold, focal_length,</div><div class="line">xyz_in_cur, inliers, outliers);</div><div class="line">T_cur_from_ref = Homography.T_c2_from_c1_;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这边给出一个提示，因为要保证16字节对齐，对于Vector2d之类的容器形式要写成 <strong>std::vector<vector2d, aligned_allocator<vector2d="">&gt;</vector2d,></strong>，对于Vector3f 或 MatrixXd之类的，则不考虑，具体可以参考<br><a href="http://eigen.tuxfamily.org/dox/group__TopicStlContainers.html" target="_blank" rel="external">http://eigen.tuxfamily.org/dox/group__TopicStlContainers.html</a><br>对于函数computeInliers首先先进行三角定位，确定两个关联特征对应的3D点，根据3D进行反投影，通过阈值对反投影的误差的关系确定内外点，具体过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">double computeInliers(const std::vector&lt;Vector3d&gt;&amp; features1, // c1</div><div class="line">const std::vector&lt;Vector3d&gt;&amp; features2, // c2</div><div class="line">const Matrix3d&amp; R,                 // R_c1_c2</div><div class="line">const Vector3d&amp; t,                 // c1_t</div><div class="line">const double reproj_thresh,</div><div class="line">double focal_length,</div><div class="line">std::vector&lt;Vector3d&gt;&amp; xyz_vec,         // in frame c1</div><div class="line">std::vector&lt;int&gt;&amp; inliers,</div><div class="line">std::vector&lt;int&gt;&amp; outliers)</div><div class="line">&#123;</div><div class="line">inliers.clear(); inliers.reserve(features1.size());</div><div class="line">outliers.clear(); outliers.reserve(features1.size());</div><div class="line">xyz_vec.clear(); xyz_vec.reserve(features1.size());</div><div class="line">double tot_error = 0;</div><div class="line">//三角化所有特征，然后计算投影误差和内点</div><div class="line">for (size_t j = 0; j&lt;features1.size(); ++j)</div><div class="line">&#123;</div><div class="line">xyz_vec.push_back(triangulateFeatureNonLin(R, t, features1[j], features2[j]));</div><div class="line">double e1 = reprojError(features1[j], xyz_vec.back(), focal_length);</div><div class="line">double e2 = reprojError(features2[j], R.transpose()*(xyz_vec.back() - t), focal_length);</div><div class="line">if (e1 &gt; reproj_thresh || e2 &gt; reproj_thresh)</div><div class="line">outliers.push_back(j);</div><div class="line">else</div><div class="line">&#123;</div><div class="line">inliers.push_back(j);</div><div class="line">tot_error += e1 + e2;</div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line">return tot_error;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>但是这边三角定位确定3D点还是有点不太明白</strong>，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">Vector3d triangulateFeatureNonLin(const Matrix3d&amp; R, const Vector3d&amp; t,</div><div class="line">const Vector3d&amp; feature1, const Vector3d&amp; feature2)</div><div class="line">&#123;</div><div class="line">Vector3d f2 = R * feature2;</div><div class="line">Vector2d b;</div><div class="line">b[0] = t.dot(feature1);</div><div class="line">b[1] = t.dot(f2);</div><div class="line">Matrix2d A;</div><div class="line">A(0, 0) = feature1.dot(feature1);</div><div class="line">A(1, 0) = feature1.dot(f2);</div><div class="line">A(0, 1) = -A(1, 0);</div><div class="line">A(1, 1) = -f2.dot(f2);</div><div class="line">Vector2d lambda = A.inverse() * b;</div><div class="line">Vector3d xm = lambda[0] * feature1;</div><div class="line">Vector3d xn = t + lambda[1] * f2;</div><div class="line">return (xm + xn) / 2;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>到这里单应矩阵的估计、分解就结束了，结束之后要对计算得到的内点数添加阈值控制，要确保内点数大于40.<br>下一步就是尺度估计，离相机的距离不同，则图像的尺度不一样，采用的方法是计算上面计算的所有3D点所有深度的中值scene_depth_median，则此时尺度为<strong>scale = 1.0 / scene_depth_median;</strong><br>    注意：1. 对于单目视觉里程计是不知道尺度信息的，也就是在第一帧的时候，我们假设了特征对应的3D点的深度为1。</p>
<ol>
<li>也就是目前是通过计算下一帧所有特征对应的3D点深度的中值作为尺度计算值，这也就限制了算法的使用场景，定位相机应尽可能的对着一个平面，所以朝地是一个很好的选择</li>
</ol>
<p>接下来计算当前帧的相机外参，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">// 计算相对变换SE3</div><div class="line">frame_cur-&gt;T_f_w_ = T_cur_from_ref_ * frame_ref_-&gt;T_f_w_;</div><div class="line"></div><div class="line">// 对位移变换添加尺度</div><div class="line">frame_cur-&gt;T_f_w_.translation() = -frame_cur-&gt;T_f_w_.rotation_matrix()*(frame_ref_-&gt;pos() + scale*(frame_cur-&gt;pos() - frame_ref_-&gt;pos()));</div><div class="line"></div></pre></td></tr></table></figure></p>
<p>这边注意要对位移变换添加尺度变换，原因是我们实际是假设深度为1的情况下进行计算，而实际深度是不是1，要转变到实际深度情况下的值。另外pos=(−R^(−1))*t<br>最后对每个内点创建3D点，设置特征，添加到这两帧中，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">SE3 T_world_cur = frame_cur-&gt;T_f_w_.inverse();</div><div class="line">for (std::vector&lt;int&gt;::iterator it = inliers_.begin(); it != inliers_.end(); ++it)</div><div class="line">&#123;</div><div class="line">Vector2d px_cur(px_cur_[*it].x, px_cur_[*it].y);</div><div class="line">Vector2d px_ref(px_ref_[*it].x, px_ref_[*it].y);</div><div class="line">if (frame_ref_-&gt;cam_-&gt;isInFrame(px_cur.cast&lt;int&gt;(), 10) &amp;&amp; frame_ref_-&gt;cam_-&gt;isInFrame(px_ref.cast&lt;int&gt;(), 10) &amp;&amp; xyz_in_cur_[*it].z() &gt; 0)</div><div class="line">&#123;</div><div class="line">Vector3d pos = T_world_cur * (xyz_in_cur_[*it] * scale);// 将相机下的点坐标转世界坐标</div><div class="line">Point3D *new_point = new Point3D(pos);</div><div class="line"></div><div class="line">Feature* ftr_cur = new Feature(frame_cur.get(), new_point, px_cur, f_cur_[*it], 0);</div><div class="line">frame_cur-&gt;addFeature(ftr_cur);</div><div class="line">// 将同一个点对应的特征保存起来，这样点删除了，对应的特征都可以删除</div><div class="line">new_point-&gt;addFrameRef(ftr_cur);</div><div class="line"></div><div class="line">Feature* ftr_ref = new Feature(frame_ref_.get(), new_point, px_ref, f_ref_[*it], 0);</div><div class="line">frame_ref_-&gt;addFeature(ftr_ref);</div><div class="line">new_point-&gt;addFrameRef(ftr_ref);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>到这里整个初始位置的确定就结束了，主要思想就是通过光流跟踪获得对应特征点对，通过对应特征点对估计单应矩阵，将单应矩阵进行分解或者相机外参数据，这个里面主要要注意的是检测到特征的点数，跟踪的特征点数，计算单应矩阵特征的内点数进行阈值限定，以及scale的估计。<br>最后写一个简单的测试程序对上述过程进行简单测试，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">int main(int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">CmdLine cmd;</div><div class="line">std::string first_frame_name;</div><div class="line">std::string second_frame_name;</div><div class="line"></div><div class="line">cmd.add(make_option(&apos;f&apos;, first_frame_name, &quot;firstname&quot;));</div><div class="line">cmd.add(make_option(&apos;s&apos;, second_frame_name, &quot;secondname&quot;));</div><div class="line">try &#123;</div><div class="line">if (argc == 1) throw std::string(&quot;Invalid command line parameter.&quot;);</div><div class="line">cmd.process(argc, argv);</div><div class="line">&#125;</div><div class="line">catch (const std::string&amp; s) &#123;</div><div class="line">std::cerr &lt;&lt; &quot;Feature detector \nUsage: &quot; &lt;&lt; argv[0] &lt;&lt; &quot;\n&quot;</div><div class="line">&lt;&lt; &quot;[-f|--firstname name]\n&quot;</div><div class="line">&lt;&lt; &quot;[-s|--secondname name]\n&quot;</div><div class="line">&lt;&lt; std::endl;</div><div class="line"></div><div class="line">std::cerr &lt;&lt; s &lt;&lt; std::endl;</div><div class="line">return EXIT_FAILURE;</div><div class="line">&#125;</div><div class="line">cv::Mat first_img(cv::imread(first_frame_name, 0));</div><div class="line">cv::Mat second_img(cv::imread(second_frame_name, 0));</div><div class="line">assert(first_img.type() == CV_8UC1 &amp;&amp; !first_img.empty());</div><div class="line">assert(second_img.type() == CV_8UC1 &amp;&amp; !second_img.empty());</div><div class="line"></div><div class="line">AbstractCamera* cam = new PinholeCamera(752, 480, 315.5, 315.5, 376.0, 240.0);</div><div class="line"></div><div class="line">FramePtr fisrt_frame(new Frame(cam, first_img, 0.0));</div><div class="line">FramePtr second_frame(new Frame(cam, second_img, 1.0));</div><div class="line"></div><div class="line">Initialization init;</div><div class="line">init.addFirstFrame(fisrt_frame);</div><div class="line">init.addSecondFrame(second_frame);</div><div class="line">std::cout &lt;&lt; second_frame-&gt;T_f_w_ &lt;&lt; std::endl;</div><div class="line"></div><div class="line">return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>结果如下：<br><img src="http://7xl6tk.com1.z0.glb.clouddn.com/initial_position.png" alt=""></p>
<h2 id="下一步计划"><a href="#下一步计划" class="headerlink" title="下一步计划"></a>下一步计划</h2><p>上面完成了初始位置的确定，下一步就开始处理连续帧，进行motion estimation和mapping。<br>[1] Faugeras O D, Lustman F. Motion and structure from motion in a piecewise planar environment[J]. International Journal of Pattern Recognition and Artificial Intelligence, 1988, 2(03): 485-508.</p>
<p>转载自冯兵的博客，<a href="http://fengbing.net/2015/08/15/%E4%B8%80%E6%AD%A5%E6%AD%A5%E5%AE%9E%E7%8E%B0%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A13%E2%80%94%E2%80%94%E5%88%9D%E5%A7%8B%E4%BD%8D%E7%BD%AE%E7%A1%AE%E5%AE%9A/" target="_blank" rel="external">原文链接</a></p>

      
    </div>
    <footer>
      
        
        
        <div class="bdsharebuttonbox">
		<a href="#" class="bds_more" data-cmd="more"></a>
		<a href="#" class="bds_qzone" data-cmd="qzone"></a>
		<a href="#" class="bds_tsina" data-cmd="tsina"></a>
		<a href="#" class="bds_tqq" data-cmd="tqq"></a>
		<a href="#" class="bds_renren" data-cmd="renren">
		</a><a href="#" class="bds_weixin" data-cmd="weixin"></a>
		</div>
<script>
window._bd_share_config={
"common":{
"bdSnsKey":{},
"bdText":"",
"bdMini":"2",
"bdPic":"",
"bdStyle":"0",
"bdSize":"16"},
"share":{},
"image":{
"viewList":[
"qzone","tsina",
"tqq","renren",
"weixin"],
"viewText":"分享到：",
"viewSize":"16"},
"selectShare":{
"bdContainerClass":null,
"bdSelectMiniList":[
"qzone","tsina","tqq",
"renren","weixin"]
}
};
with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<!-- 页面导航 -->
 <nav id="pagination" >
    
    <a href="/2017/09/18/一步步完善视觉里程计4——运动估计image-align/" class="alignleft prev" >Prev</a>
    
    
    <a href="/2017/09/17/一步步完善视觉里程计2——FAST特征检测/" class="alignright next" >Next</a>
    
    <div class="clearfix"></div>
</nav>
<section id="comment">
<!-- 多说评论框 start -->
	<div class="ds-thread" data-category="<#article/category/id#>" data-thread-key="<#article/id#>" data-title="<#article/title#>" data-author-key="<#article/author/id#>"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"aichimantou"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->

</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:blog.blackant.org">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/robot/Java/Android/">Android</a><small>1</small></li>
  
    <li><a href="/categories/robot/Java/">Java</a><small>1</small></li>
  
    <li><a href="/categories/algorithm/">algorithm</a><small>1</small></li>
  
    <li><a href="/categories/robot/">robot</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/SAE/" style="font-size: 10px;">SAE</a> <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/directions/" style="font-size: 10px;">directions</a> <a href="/tags/donation/" style="font-size: 10px;">donation</a> <a href="/tags/goal/" style="font-size: 20px;">goal</a> <a href="/tags/hello/" style="font-size: 10px;">hello</a> <a href="/tags/helloworld/" style="font-size: 10px;">helloworld</a> <a href="/tags/robot/" style="font-size: 10px;">robot</a>
  </div>
</div>


  <div class="widget tag">
<h3 class="title">Link</h3>
<ul class="entry">
<li><a href="http://baidu.com/" title="Baidu Corportion">iRobot</a></li>
<li><a href="http://baidu.com/" title="Baidu Corportion">Rocket</a></li>
<li><a href="http://baidu.com/" title="Baidu Corportion">FFmpeg</a></li>
</ul>
</div>
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 ZhuChaozheng SunTong ChuZhefan
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>